server:
  port: 8081
  servlet:
    context-path: /engines

spring:
  application:
    name: moneyplant-engines
  
  profiles:
    active: local
  
  # CORS Configuration for frontend access
  web:
    cors:
      allowed-origins: http://localhost:4200,http://127.0.0.1:4200
      allowed-methods: GET,POST,PUT,DELETE,OPTIONS,PATCH
      allowed-headers: "*"
      allow-credentials: true
      max-age: 3600
  
  datasource:
    url: ${TIMESCALEDB_URL:jdbc:postgresql://postgres.tailce422e.ts.net:5432/MoneyPlant}
    username: ${TIMESCALEDB_USERNAME:postgres}
    password: ${TIMESCALEDB_PASSWORD:mysecretpassword}
    driver-class-name: org.postgresql.Driver
    hikari:
      connection-timeout: 30000
      maximum-pool-size: 10
      minimum-idle: 2
      idle-timeout: 600000
      max-lifetime: 1800000
      connection-init-sql: SET SESSION default_transaction_isolation = 'read committed'
      # Additional connection properties for external database
      connection-test-query: SELECT 1
      # SSL configuration for external database
      data-source-properties:
        ssl: false
        sslmode: disable
      # Connection validation settings
      validation-timeout: 5000
      leak-detection-threshold: 60000
      auto-commit: false


  jpa:
    hibernate:
      ddl-auto: validate  # Use 'validate' to prevent schema changes on existing database
    show-sql: false
    # Transaction management configuration
    open-in-view: false
    
    # Explicit transaction management settings
    defer-datasource-initialization: false
    
    properties:
      hibernate:
        format_sql: true
        
        # Connection and transaction management
        connection:
          auto_commit: false
          provider_disables_autocommit: true
          isolation_level: READ_COMMITTED
        
        # JDBC settings
        jdbc:
          batch_size: 20
          time_zone: UTC
          fetch_size: 50
        
        # Transaction settings
        transaction:
          jta:
            platform: org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform
          flush_mode: AUTO
          default_auto_commit: false
        
        # Session management
        current_session_context_class: thread
        session:
          events:
            log: false
        
        # Performance settings
        order_inserts: true
        order_updates: true
        batch_versioned_data: true
        
        # Dialect not explicitly set; Hibernate will auto-detect PostgreSQL dialect as per HHH90000025 guidance

  # Kafka configuration
  kafka:
    enabled: true
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9093}
    schema-registry-url: ${KAFKA_SCHEMA_REGISTRY_URL:http://localhost:8081}
    producer:
      acks: all
      retries: 3
      batch-size: 16384
      linger-ms: 10
      buffer-memory: 33554432
      compression-type: snappy
      max-in-flight-requests: 5
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      properties:
        schema.registry.url: ${KAFKA_SCHEMA_REGISTRY_URL:http://localhost:8081}
    consumer:
      group-id: moneyplant-engines
      auto-offset-reset: earliest
      enable-auto-commit: true
      auto-commit-interval-ms: 1000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        schema.registry.url: ${KAFKA_SCHEMA_REGISTRY_URL:http://localhost:8081}
        specific.avro.reader: true
  
  boot:
    admin:
      client:
        url: http://localhost:8080

# Transaction management configuration
  transaction:
    default-timeout: 30s
    rollback-on-commit-failure: true

# Kafka topic configuration
kafka:
  topics:
    nse-indices-ticks: nse-indices-ticks
    market-data: market-data
    market-data-ticks: market-data-ticks
    market-data-candles: market-data-candles
    data-quality-alerts: data-quality-alerts
    symbol-universe-updates: symbol-universe-updates
    trading-signals: trading-signals
    backtest-results: backtest-results
  group-id: moneyplant-engines

# Ingestion Engine Configuration
ingestion:
  auto-start:
    enabled: false  # Set to true to enable auto-start for ingestion services
    delay-seconds: 10  # Delay before starting ingestion (allows other services to initialize)
  
  providers:
    nse:
      enabled: ${INGESTION_NSE_ENABLED:true}
      api-url: ${INGESTION_NSE_API_URL:https://www.nseindia.com/api}
      rate-limit-per-hour: ${INGESTION_NSE_RATE_LIMIT:1000}
      timeout-sec: ${INGESTION_NSE_TIMEOUT:15}
      retry-attempts: ${INGESTION_NSE_RETRY_ATTEMPTS:3}
      headers:
        user-agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        accept: "application/json"
        accept-language: "en-US,en;q=0.9"
        accept-encoding: "gzip, deflate, br"
    
    yahoo:
      enabled: ${INGESTION_YAHOO_ENABLED:true}
      api-url: ${INGESTION_YAHOO_API_URL:https://query1.finance.yahoo.com}
      rate-limit-per-hour: ${INGESTION_YAHOO_RATE_LIMIT:2000}
      timeout-sec: ${INGESTION_YAHOO_TIMEOUT:10}
      retry-attempts: ${INGESTION_YAHOO_RETRY_ATTEMPTS:3}
      # Yahoo Finance API configuration
      endpoints:
        quote: /v8/finance/quote
        chart: /v8/finance/chart/{symbol}
        historical: /v7/finance/download/{symbol}
      # Query parameters
      params:
        interval: 1d
        range: 1mo
        events: history
  
  storage:
    batch-size: 1000
    flush-interval-ms: 5000
    archival:
      enabled: true
      schedule-cron: "0 0 12 * * MON-FRI"  # 5:30 PM IST = 12:00 PM UTC (noon)
      verify-integrity: true
      auto-truncate: true
  
  performance:
    parallelism: 10
    buffer-size: 10000

# NSE WebSocket configuration
nse:
  websocket:
    # NSE WebSocket endpoints (multiple options for different data streams)
    url: wss://www.nseindia.com/streams/indices/high/drdMkt
    # Alternative endpoints if the main one fails
    alternative-urls:
      - wss://www.nseindia.com/streams/indices/high/drdMkt
      - wss://www.nseindia.com/streams/indices/low/drdMkt
      - wss://www.nseindia.com/streams/indices/open/drdMkt
    reconnect:
      interval: 30
      max-attempts: 5
      backoff-multiplier: 2
    enabled: true  # Enable NSE WebSocket connection for real data
    timeout: 30000  # Connection timeout in milliseconds
    heartbeat-interval: 30000  # Heartbeat interval in milliseconds
    # Authentication and headers configuration
    headers:
      user-agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
      origin: "https://www.nseindia.com"
      referer: "https://www.nseindia.com/get-quotes/equity"
      accept: "*/*"
      accept-language: "en-US,en;q=0.9"
      accept-encoding: "gzip, deflate, br"
      connection: "keep-alive"
      upgrade: "websocket"
      sec-websocket-version: "13"
      sec-websocket-key: ""
      sec-websocket-protocol: ""
    fallback:
      enabled: true  # Enable fallback to mock data when NSE connection fails
      mock-interval: 5000  # Generate mock data every 5 seconds when fallback is active
  
  # Auto-start configuration for NSE indices ingestion
  auto-start:
    enabled: true  # Set to false to disable auto-start
    delay-seconds: 10  # Delay before starting ingestion (allows other services to initialize)

# Spark Configuration
spark:
  app-name: MoneyPlant-Engines
  # Use external Spark cluster instead of local mode
  master: spark://spark-master.tailce422e.ts.net:7077
  # Spark Master UI available at: http://spark-master.tailce422e.ts.net:8080/
  driver-memory: 2g
  executor-memory: 2g
  executor-cores: 2
  executor-instances: 2
  sql:
    adaptive:
      enabled: true
      coalescePartitions:
        enabled: true
      skewJoin:
        enabled: true
      localShuffleReader:
        enabled: true
      optimizeSkewedJoin:
        enabled: true

# Trino Configuration
trino:
  url: jdbc:trino://trino.tailce422e.ts.net:8080
  username: trino
  password: 
  catalog: 
  schema: 
  connection-pool:
    maximum-pool-size: 10
    minimum-idle: 2
    connection-timeout: 30000
    idle-timeout: 600000
    max-lifetime: 1800000

# Apache Hudi Configuration
hudi:
  base-path: ${HUDI_BASE_PATH:/tmp/hudi/nse-eq-ticks}
  table-name: nse_eq_ticks_historical
  key-generator: org.apache.hudi.keygen.SimpleKeyGenerator
  partition-path-field: date
  # S3/MinIO Configuration
  s3:
    endpoint: ${HUDI_S3_ENDPOINT:http://localhost:9000}
    access-key: ${HUDI_S3_ACCESS_KEY:minioadmin}
    secret-key: ${HUDI_S3_SECRET_KEY:minioadmin}
    bucket: ${HUDI_S3_BUCKET:moneyplant-datalake}
    path-style-access: true
  write-options:
    table-type: COPY_ON_WRITE
    recordkey-field: symbol,timestamp
    partitionpath-field: date
    precombine-field: timestamp
    keygenerator-class: org.apache.hudi.keygen.SimpleKeyGenerator
    hive-style-partitioning: true
    operation: upsert
    table-name: nse_eq_ticks_historical
    base-path: ${HUDI_BASE_PATH:/tmp/hudi/nse-eq-ticks}
    parallelism: 4
    inline-compaction: false
    max-delta-commits-before-compaction: 10
    # S3/MinIO specific options
    hoodie.datasource.write.storage.type: ${HUDI_STORAGE_TYPE:COPY_ON_WRITE}
    hoodie.datasource.write.recordkey.field: symbol,timestamp
    hoodie.datasource.write.partitionpath.field: date
    hoodie.datasource.write.precombine.field: timestamp
  hive-metastore:
    enabled: ${HUDI_HIVE_METASTORE_ENABLED:true}
    uris: ${HUDI_HIVE_METASTORE_URIS:thrift://localhost:9083}
    database: ${HUDI_HIVE_DATABASE:default}
    table: nse_eq_ticks_historical
    partition-fields: date
    partition-extractor-class: org.apache.hudi.hive.MultiPartKeysValueExtractor
    jdbc-url: ${HUDI_HIVE_JDBC_URL:jdbc:hive2://localhost:10000}
    username: ${HUDI_HIVE_USERNAME:hive}
    password: ${HUDI_HIVE_PASSWORD:}

# Apache Iceberg Configuration
iceberg:
  catalog-name: iceberg_catalog
  warehouse-location: /tmp/iceberg
  io-impl: org.apache.iceberg.aws.s3.S3FileIO
  s3:
    endpoint: 
    access-key: 
    secret-key: 
  catalog-properties:
    catalog-impl: org.apache.iceberg.aws.glue.GlueCatalog
    warehouse: /tmp/iceberg
    io-impl: org.apache.iceberg.aws.s3.S3FileIO
  table-properties:
    write.format.default: parquet
    write.parquet.compression: snappy
    write.parquet.row-group-size-bytes: 134217728
    write.parquet.page-size-bytes: 1048576
    write.parquet.dict-size-bytes: 2097152

# Logging configuration
logging:
  level:
    root: WARN
    com.moneyplant.engines: WARN
    org.springframework.kafka: WARN
    org.apache.kafka: WARN
    org.springframework.web.socket: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# Management endpoints
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: true
